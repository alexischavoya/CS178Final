{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 178 Project part 1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mltools as ml\n",
    "import sys\n",
    "sys.path.append('code')\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_error(learner, data):\n",
    "    Xtr,Xte,Ytr,Yte = data\n",
    "    print(\"Trainning error = \",learner.err(Xtr,Ytr))\n",
    "    print(\"Testing error = \",learner.err(Xte,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(learner,data,file=\"\"):\n",
    "    Xtr,Xte,Ytr,Yte = data\n",
    "    fpr,tpr,tnr = learner.roc(Xtr,Ytr)\n",
    "    plt.plot(fpr,tpr, label=\"training roc\")\n",
    "    fpr,tpr,tnr = learner.roc(Xte,Yte)\n",
    "    plt.plot(fpr,tpr,label=\"testing roc\")\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.legend()\n",
    "    if(file != \"\"):\n",
    "        plt.savefig('output/{}.png'.format(file))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_output(learner,filename =\"output\",feature_space = [i for i in range(X.shape[1])]):\n",
    "    Xte = np.genfromtxt('data/X_test.txt', delimiter=',')\n",
    "    Xte = Xte[:,feature_space]\n",
    "    Yte = np.vstack((np.arange(Xte.shape[0]), learner.predictSoft(Xte)[:,1])).T\n",
    "    np.savetxt(\"{}.txt\".format(filename),Yte,'%d, %.2f',header='Id,Predicted',comments='',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "data = Xtr,Xte,Ytr,Yte = ml.splitData(X,Y,0.75) #75%training and 25% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_knn = ml.knn.knnClassify()\n",
    "naive_knn.train(Xtr,Ytr)\n",
    "naive_knn.K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=2^4=16 seems like a good choice, we will stick to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tr_error = []\n",
    "knn_te_error = []\n",
    "k_values = [2**i for i in range(10)]\n",
    "for k in k_values:\n",
    "    naive_knn.K = k\n",
    "    knn_tr_error.append(naive_knn.err(Xtr,Ytr))\n",
    "    knn_te_error.append(naive_knn.err(Xte,Yte))\n",
    "    print(\"k = {} done.\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10),knn_tr_error, label= \"training error\")\n",
    "plt.plot(range(10),knn_te_error, label= \"testing error\")\n",
    "plt.title(\"k value vs error rate\")\n",
    "plt.xlabel(\"K value = 2**x\")\n",
    "plt.ylabel(\"error rate\")\n",
    "plt.savefig('output/kvalue_error.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, naive Knn does not seem doing well, need some feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First come into mind is the emsemble technique, which pick only a portion of feature to the leaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with limited feature enabled\n",
    "class KNN_f(ml.knn.knnClassify):\n",
    "    def __init__(self, X=None, Y=None,features = 1, K=1):\n",
    "        self.selected_feature = sorted( np.random.choice(range(X.shape[1]),features , replace=False) )\n",
    "        ml.knn.knnClassify.__init__(self,X[:,self.selected_feature],Y,K)\n",
    "    \n",
    "    def predictSoft(self,X):\n",
    "        if(X.shape[1] == len(self.selected_feature)):\n",
    "            return ml.knn.knnClassify.predictSoft(self,X)\n",
    "        return ml.knn.knnClassify.predictSoft(self,X[:,self.selected_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_knn(ml.classifier):\n",
    "    def __init__(self,Xtr,Ytr,nbags=1,features=1,K = 1, partition = 1):\n",
    "        self.classifiers = [ None ] * nbags # Allocate space for learners\n",
    "        self.features_number = features\n",
    "        self.nbags = nbags\n",
    "        self.n_boot = X.shape[0]//partition\n",
    "        self.classes = list(np.unique(Ytr))\n",
    "        for i in range(nbags):\n",
    "            Xi, Yi = ml.bootstrapData(Xtr,Ytr,self.n_boot)\n",
    "            knn_f = ml.knn.knnClassify(Xi, Yi,K)\n",
    "            self.classifiers[i]=knn_f\n",
    "            \n",
    "    def predictSoft(self,X):\n",
    "        Y = np.zeros( (X.shape[0], self.nbags,2) )\n",
    "        for i in range(self.nbags):\n",
    "            Y[:,i] = self.classifiers[i].predictSoft(X)\n",
    "        return np.mean(Y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_list = []\n",
    "nbags = [2**i for i in range(12)]\n",
    "for nb in nbags:\n",
    "    a = E_knn(Xtr,Ytr,nb,107,1,100)\n",
    "    auc_list.append(a.auc(Xte,Yte))\n",
    "    print(\"nb = {} done.\".format(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"number of learner vs AUC value\")\n",
    "plt.xlabel(\"number of learner = 2**x\")\n",
    "plt.ylabel(\"AUC value\")\n",
    "plt.plot(auc_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10),knn_tr_error, label= \"training error\")\n",
    "plt.plot(range(10),knn_te_error, label= \"testing error\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"K value = 2**x\")\n",
    "plt.ylabel(\"error rate\")\n",
    "plt.savefig('output/knn.png')\n",
    "plt.title(\"k value vs error rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(auc_list,label = \"testing auc\")\n",
    "plt.xlabel(\"number of learner (2**x)\")\n",
    "plt.ylabel(\"AUC value\")\n",
    "plt.legend()\n",
    "plt.title(\"number of learner vs AUC value\")\n",
    "plt.savefig('output/eknn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_knn_limited(ml.classifier):\n",
    "    def __init__(self,Xtr,Ytr,nbags=1,features=1,K = 1, partition = 1):\n",
    "        self.classifiers = [ None ] * nbags # Allocate space for learners\n",
    "        self.features_number = features\n",
    "        self.nbags = nbags\n",
    "        self.n_boot = X.shape[0]//partition\n",
    "        self.classes = list(np.unique(Ytr))\n",
    "        for i in range(nbags):\n",
    "            Xi, Yi = ml.bootstrapData(Xtr,Ytr,self.n_boot)\n",
    "            knn_f = ml.knn.KNN_f(Xi, Yi,features,K)\n",
    "            self.classifiers[i]=knn_f\n",
    "            \n",
    "    def predictSoft(self,X):\n",
    "        Y = np.zeros( (X.shape[0], self.nbags,2) )\n",
    "        for i in range(self.nbags):\n",
    "            Y[:,i] = self.classifiers[i].predictSoft(X)\n",
    "        return np.mean(Y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_list_limited = []\n",
    "features = [(107//(2*i)) for i in range(1,10)]\n",
    "for f in features:\n",
    "    a = E_knn(Xtr,Ytr,256,f,1,100)\n",
    "    auc_list_limited.append(a.auc(Xte,Yte))\n",
    "    print(\"feature = {} done.\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(features,auc_list_limited,label = \"testing auc\")\n",
    "plt.xlabel(\"number of feature used (2**x)\")\n",
    "plt.ylabel(\"AUC value\")\n",
    "plt.title(\"number of features used vs AUC value\")\n",
    "plt.savefig('output/feature_auc.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_list_limited_new = []\n",
    "new_features = [i for i in range(17,26)]\n",
    "for f in new_features:\n",
    "    a = E_knn(Xtr,Ytr,256,f,1,100)\n",
    "    auc_list_limited_new.append(a.auc(Xte,Yte))\n",
    "    print(\"feature = {} done.\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_features,auc_list_limited_new,label = \"testing auc\")\n",
    "plt.title(\"number of features used vs AUC value\")\n",
    "plt.ylabel(\"AUC value\")\n",
    "plt.legend()\n",
    "plt.savefig('output/auc_2.png')\n",
    "plt.title(\"number of feature vs AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = E_knn(Xtr,Ytr,256,21,1,100)\n",
    "plot_roc(a,data,\"roc_f21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_output(a,\"knn_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature #  0 done\n",
      "feature #  1 done\n",
      "feature #  2 done\n",
      "feature #  3 done\n",
      "feature #  4 done\n",
      "feature #  5 done\n",
      "feature #  6 done\n",
      "feature #  7 done\n",
      "feature #  8 done\n",
      "feature #  9 done\n",
      "feature #  10 done\n",
      "feature #  11 done\n",
      "feature #  12 done\n",
      "feature #  13 done\n",
      "feature #  14 done\n",
      "feature #  15 done\n",
      "feature #  16 done\n",
      "feature #  17 done\n",
      "feature #  18 done\n",
      "feature #  19 done\n",
      "feature #  20 done\n",
      "feature #  21 done\n",
      "feature #  22 done\n",
      "feature #  23 done\n",
      "feature #  24 done\n",
      "feature #  25 done\n",
      "feature #  26 done\n",
      "feature #  27 done\n",
      "feature #  28 done\n",
      "feature #  29 done\n",
      "feature #  30 done\n",
      "feature #  31 done\n",
      "feature #  32 done\n",
      "feature #  33 done\n",
      "feature #  34 done\n",
      "feature #  35 done\n",
      "feature #  36 done\n",
      "feature #  37 done\n",
      "feature #  38 done\n",
      "feature #  39 done\n",
      "feature #  40 done\n",
      "feature #  41 done\n",
      "feature #  42 done\n",
      "feature #  43 done\n",
      "feature #  44 done\n",
      "feature #  45 done\n",
      "feature #  46 done\n",
      "feature #  47 done\n",
      "feature #  48 done\n",
      "feature #  49 done\n",
      "feature #  50 done\n",
      "feature #  51 done\n",
      "feature #  52 done\n",
      "feature #  53 done\n",
      "feature #  54 done\n",
      "feature #  55 done\n",
      "feature #  56 done\n",
      "feature #  57 done\n",
      "feature #  58 done\n",
      "feature #  59 done\n",
      "feature #  60 done\n",
      "feature #  61 done\n",
      "feature #  62 done\n",
      "feature #  63 done\n",
      "feature #  64 done\n",
      "feature #  65 done\n",
      "feature #  66 done\n",
      "feature #  67 done\n",
      "feature #  68 done\n",
      "feature #  69 done\n",
      "feature #  70 done\n",
      "feature #  71 done\n",
      "feature #  72 done\n",
      "feature #  73 done\n",
      "feature #  74 done\n",
      "feature #  75 done\n",
      "feature #  76 done\n",
      "feature #  77 done\n",
      "feature #  78 done\n",
      "feature #  79 done\n",
      "feature #  80 done\n",
      "feature #  81 done\n",
      "feature #  82 done\n",
      "feature #  83 done\n",
      "feature #  84 done\n",
      "feature #  85 done\n",
      "feature #  86 done\n",
      "feature #  87 done\n",
      "feature #  88 done\n",
      "feature #  89 done\n",
      "feature #  90 done\n",
      "feature #  91 done\n",
      "feature #  92 done\n",
      "feature #  93 done\n",
      "feature #  94 done\n",
      "feature #  95 done\n",
      "feature #  96 done\n",
      "feature #  97 done\n",
      "feature #  98 done\n",
      "feature #  99 done\n",
      "feature #  100 done\n",
      "feature #  101 done\n",
      "feature #  102 done\n",
      "feature #  103 done\n",
      "feature #  104 done\n",
      "feature #  105 done\n",
      "feature #  106 done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 833.],\n",
       "       [3472.],\n",
       "       [1316.],\n",
       "       ...,\n",
       "       [ 560.],\n",
       "       [1449.],\n",
       "       [ 966.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr[:,0].reshape(Xtr.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.genfromtxt('feature_score.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5237068965517241"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(tr[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "np.random.seed(0)\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "preprocessing.normalize(X,axis=0)[0]\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "data = Xtr,Xte,Ytr,Yte = ml.splitData(X,Y,0.5) #75%training and 25% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5764513395169264"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = ml.knn.knnClassify()\n",
    "knn.train(Xtr[:,[28, 44, 49, 74, 54, 68, 73, 70, 60, 94, 57, 1, 43, 53, 10, 71, 42, 56]  ],Ytr)\n",
    "knn.k = 1\n",
    "knn.auc(Xte[:,[28, 44, 49, 74, 54, 68, 73, 70, 60, 94, 57, 1, 43, 53, 10, 71, 42, 56]  ],Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_output(knn,\"knnout_18_features\",feature_space=[28, 44, 49, 74, 54, 68, 73, 70, 60, 94, 57, 1, 43, 53, 10, 71, 42, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
